{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Kuzu graph database of webpages/links that Brad is interested in. \n",
    "# Visualized with yFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 1: DATA CREATION AND LLM CALLS\n",
    "# --------------------------------------\n",
    "# This section fetches webpage content, extracts titles, and uses an LLM to categorize and extract keywords,\n",
    "# producing the final links_with_metadata.csv file for use in the KÃ¹zu database section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "from ollama import Client\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import kuzu\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved to links.csv\n",
      "Total links: 63\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1: Generate links.csv with only URLs\n",
    "import pandas as pd\n",
    "links_data = [\n",
    "    {\"url\": \"https://speakerdeck.com/gaelvaroquaux/open-source-software-how-to-live-long-and-go-far\"},\n",
    "    {\"url\": \"https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985\"},\n",
    "    {\"url\": \"https://github.com/jackboyla/GLiREL\"},\n",
    "    {\"url\": \"https://www.latencyconf.io/sessions/pandas-should-go-extinct\"},\n",
    "    {\"url\": \"https://orbae.adastra.eco/\"},\n",
    "    {\"url\": \"https://cambridge-intelligence.com/mapweave/\"},\n",
    "    {\"url\": \"https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql\"},\n",
    "    {\"url\": \"https://holonetgalacticmap-frontend.vercel.app/sparql\"},\n",
    "    {\"url\": \"https://arxiv.org/pdf/2502.13025\"},\n",
    "    {\"url\": \"https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63\"},\n",
    "    {\"url\": \"https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs\"},\n",
    "    {\"url\": \"https://enterprise-knowledge.com/the-resource-description-framework-rdf/\"},\n",
    "    {\"url\": \"https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530\"},\n",
    "    {\"url\": \"https://blog.kuzudb.com/post/kuzu-wasm-rag/\"},\n",
    "    {\"url\": \"https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/\"},\n",
    "    {\"url\": \"https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f\"},\n",
    "    {\"url\": \"https://github.com/Manirevuri/arangodb-hackathon\"},\n",
    "    {\"url\": \"https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51\"},\n",
    "    {\"url\": \"https://2024.connected-data.london/speakers/urbashi-mitra/\"},\n",
    "    {\"url\": \"https://darrendevitt.com/all-fhir-concepts-can-be-explained-simply/\"},\n",
    "    {\"url\": \"https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e\"},\n",
    "    {\"url\": \"https://www.sciencedirect.com/science/article/pii/S1532046422002064\"},\n",
    "    {\"url\": \"https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98\"},\n",
    "    {\"url\": \"https://link.springer.com/journal/10506\"},\n",
    "    {\"url\": \"https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/\"},\n",
    "    {\"url\": \"https://www.occrp.org/en/project/cyprus-confidential/billionaire-roman-abramovichs-company-set-up-fake-superyacht-chartering-scheme-in-apparent-attempt-to-evade-millions-in-taxes\"},\n",
    "    {\"url\": \"https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine\"},\n",
    "    {\"url\": \"https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data\"},\n",
    "    {\"url\": \"https://discuss.opensanctions.org/\"},\n",
    "    {\"url\": \"https://blog.opencorporates.com/2025/02/13/getting-started-with-the-opencorporates-api/\"},\n",
    "    {\"url\": \"https://www.buzzsprout.com/242645/episodes/16799543\"},\n",
    "    {\"url\": \"https://www.unodc.org/unodc/en/data-and-analysis/tip-studies.html\"},\n",
    "    {\"url\": \"https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7\"},\n",
    "    {\"url\": \"https://www.occrp.org/en/project/scam-empire/scam-operations-relied-on-third-party-marketing-companies-for-steady-stream-of-potential-victims\"},\n",
    "    {\"url\": \"https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md\"},\n",
    "    {\"url\": \"https://bods-data.openownership.org/source/gleif_version_0_4/\"},\n",
    "    {\"url\": \"https://eiti.org/using-eiti-data\"},\n",
    "    {\"url\": \"https://mweiti.gov.mw/index.php/reports/details/761\"},\n",
    "    {\"url\": \"https://globalenergymonitor.org/projects/global-energy-ownership-tracker/\"},\n",
    "    {\"url\": \"https://www.moodys.com/web/en/us/kyc/resources/insights/how-ai-is-enhancing-ubo-discovery-and-support-reporting-requirements-globally.html\"},\n",
    "    {\"url\": \"https://oecdstatistics.blog/2019/07/04/the-adima-database-on-multinational-enterprises/\"},\n",
    "    {\"url\": \"https://oecdstatistics.blog/2025/02/21/monitoring-multinational-enterprises-how-the-oecd-and-unsd-are-harnessing-open-data/\"},\n",
    "    {\"url\": \"https://www.taxobservatory.eu/publication/the-end-of-londongrad-ownership-transparency-and-offshore-investment-in-real-estate/\"},\n",
    "    {\"url\": \"https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_a_new_era_of_private_sector_collaboration_to_detect_economic_crime_-_policy_discussion_paper_-_march_2025_-_final.pdf\"},\n",
    "    {\"url\": \"https://www.kharon.com/brief/outbound-investment-rules-china-hong-kong\"},\n",
    "    {\"url\": \"https://www.gao.gov/products/gao-25-107403\"},\n",
    "    {\"url\": \"https://hoeringsportalen.dk/Hearing/Details/69602\"},\n",
    "    {\"url\": \"https://ubm.se/publikationer/publikationer/2025-03-13-kunskapsrapport---avancerade-angrepp-mot-valfardssystemen\"},\n",
    "    {\"url\": \"https://senzing.com/daniel-silva-prudential-senzing-global-user-conference/\"},\n",
    "    {\"url\": \"https://graphaware.com/resources/streamlining-criminal-assets-confiscation/\"},\n",
    "    {\"url\": \"https://graphaware.com/law-enforcement/\"},\n",
    "    {\"url\": \"https://graphaware.com/blog/aml-investigations-detecting-risk-transactions/\"},\n",
    "    {\"url\": \"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5120765\"},\n",
    "    {\"url\": \"https://www.powermag.com/software-hardware-innovation-all-needed-to-upgrade-the-power-grid/\"},\n",
    "    {\"url\": \"https://wattclarity.com.au/articles/2025/02/nemde-nightmares-parallel-pathways-and-clashing-constraints/\"},\n",
    "    {\"url\": \"https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf\"},\n",
    "    {\"url\": \"https://github.com/kyribaker/7bus_LMPs\"},\n",
    "    {\"url\": \"https://www.ercot.com/content/cdr/html/real_time_system_conditions.html\"},\n",
    "    {\"url\": \"https://www.abc.net.au/news/2024-10-13/australian-coal-plant-in-extraordinary-survival-experiment/104461504\"},\n",
    "    {\"url\": \"https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind\"},\n",
    "    {\"url\": \"https://blog.gridstatus.io/curtailment/\"},\n",
    "    {\"url\": \"https://blog.gridstatus.io/spp-expansion-west/\"},\n",
    "    {\"url\": \"https://www.eia.gov/outlooks/steo/\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(links_data)\n",
    "csv_path = \"links.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"CSV saved to {csv_path}\")\n",
    "print(f\"Total links: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching content and title for https://speakerdeck.com/gaelvaroquaux/open-source-software-how-to-live-long-and-go-far...\n",
      "Fetching content and title for https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985...\n",
      "Fetching content and title for https://github.com/jackboyla/GLiREL...\n",
      "Fetching content and title for https://www.latencyconf.io/sessions/pandas-should-go-extinct...\n",
      "Fetching content and title for https://orbae.adastra.eco/...\n",
      "Fetching content and title for https://cambridge-intelligence.com/mapweave/...\n",
      "Fetching content and title for https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql...\n",
      "Fetching content and title for https://holonetgalacticmap-frontend.vercel.app/sparql...\n",
      "Insufficient content for https://holonetgalacticmap-frontend.vercel.app/sparql: 0 characters\n",
      "Fetching content and title for https://arxiv.org/pdf/2502.13025...\n",
      "Insufficient content for https://arxiv.org/pdf/2502.13025: 0 characters\n",
      "Fetching content and title for https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63...\n",
      "Fetching content and title for https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs...\n",
      "Fetching content and title for https://enterprise-knowledge.com/the-resource-description-framework-rdf/...\n",
      "Fetching content and title for https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530...\n",
      "Fetching content and title for https://blog.kuzudb.com/post/kuzu-wasm-rag/...\n",
      "Fetching content and title for https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/...\n",
      "Fetching content and title for https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f...\n",
      "Fetching content and title for https://github.com/Manirevuri/arangodb-hackathon...\n",
      "Fetching content and title for https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51...\n",
      "Fetching content and title for https://2024.connected-data.london/speakers/urbashi-mitra/...\n",
      "Fetching content and title for https://darrendevitt.com/all-fhir-concepts-can-be-explained-simply/...\n",
      "Fetching content and title for https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e...\n",
      "Fetching content and title for https://www.sciencedirect.com/science/article/pii/S1532046422002064...\n",
      "Attempt 1 failed for https://www.sciencedirect.com/science/article/pii/S1532046422002064: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/pii/S1532046422002064, content length: 899332\n",
      "Attempt 2 failed for https://www.sciencedirect.com/science/article/pii/S1532046422002064: 403 Client Error: Forbidden for url: https://www.sciencedirect.com/science/article/pii/S1532046422002064, content length: 899332\n",
      "Fetching content and title for https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98...\n",
      "Fetching content and title for https://link.springer.com/journal/10506...\n",
      "Fetching content and title for https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/...\n",
      "Fetching content and title for https://www.occrp.org/en/project/cyprus-confidential/billionaire-roman-abramovichs-company-set-up-fake-superyacht-chartering-scheme-in-apparent-attempt-to-evade-millions-in-taxes...\n",
      "Fetching content and title for https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine...\n",
      "Fetching content and title for https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data...\n",
      "Fetching content and title for https://discuss.opensanctions.org/...\n",
      "Fetching content and title for https://blog.opencorporates.com/2025/02/13/getting-started-with-the-opencorporates-api/...\n",
      "Fetching content and title for https://www.buzzsprout.com/242645/episodes/16799543...\n",
      "Fetching content and title for https://www.unodc.org/unodc/en/data-and-analysis/tip-studies.html...\n",
      "Fetching content and title for https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7...\n",
      "Fetching content and title for https://www.occrp.org/en/project/scam-empire/scam-operations-relied-on-third-party-marketing-companies-for-steady-stream-of-potential-victims...\n",
      "Fetching content and title for https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md...\n",
      "Fetching content and title for https://bods-data.openownership.org/source/gleif_version_0_4/...\n",
      "Fetching content and title for https://eiti.org/using-eiti-data...\n",
      "Fetching content and title for https://mweiti.gov.mw/index.php/reports/details/761...\n",
      "Fetching content and title for https://globalenergymonitor.org/projects/global-energy-ownership-tracker/...\n",
      "Fetching content and title for https://www.moodys.com/web/en/us/kyc/resources/insights/how-ai-is-enhancing-ubo-discovery-and-support-reporting-requirements-globally.html...\n",
      "Fetching content and title for https://oecdstatistics.blog/2019/07/04/the-adima-database-on-multinational-enterprises/...\n",
      "Fetching content and title for https://oecdstatistics.blog/2025/02/21/monitoring-multinational-enterprises-how-the-oecd-and-unsd-are-harnessing-open-data/...\n",
      "Fetching content and title for https://www.taxobservatory.eu/publication/the-end-of-londongrad-ownership-transparency-and-offshore-investment-in-real-estate/...\n",
      "Fetching content and title for https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_a_new_era_of_private_sector_collaboration_to_detect_economic_crime_-_policy_discussion_paper_-_march_2025_-_final.pdf...\n",
      "Insufficient content for https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_a_new_era_of_private_sector_collaboration_to_detect_economic_crime_-_policy_discussion_paper_-_march_2025_-_final.pdf: 0 characters\n",
      "Fetching content and title for https://www.kharon.com/brief/outbound-investment-rules-china-hong-kong...\n",
      "Fetching content and title for https://www.gao.gov/products/gao-25-107403...\n",
      "Fetching content and title for https://hoeringsportalen.dk/Hearing/Details/69602...\n",
      "Fetching content and title for https://ubm.se/publikationer/publikationer/2025-03-13-kunskapsrapport---avancerade-angrepp-mot-valfardssystemen...\n",
      "Fetching content and title for https://senzing.com/daniel-silva-prudential-senzing-global-user-conference/...\n",
      "Fetching content and title for https://graphaware.com/resources/streamlining-criminal-assets-confiscation/...\n",
      "Fetching content and title for https://graphaware.com/law-enforcement/...\n",
      "Fetching content and title for https://graphaware.com/blog/aml-investigations-detecting-risk-transactions/...\n",
      "Fetching content and title for https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5120765...\n",
      "Fetching content and title for https://www.powermag.com/software-hardware-innovation-all-needed-to-upgrade-the-power-grid/...\n",
      "Fetching content and title for https://wattclarity.com.au/articles/2025/02/nemde-nightmares-parallel-pathways-and-clashing-constraints/...\n",
      "Fetching content and title for https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf...\n",
      "Attempt 1 failed for https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf: 403 Client Error: Forbidden for url: https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf, content length: 118\n",
      "Attempt 2 failed for https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf: 403 Client Error: Forbidden for url: https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf, content length: 118\n",
      "Fetching content and title for https://github.com/kyribaker/7bus_LMPs...\n",
      "Fetching content and title for https://www.ercot.com/content/cdr/html/real_time_system_conditions.html...\n",
      "Insufficient content for https://www.ercot.com/content/cdr/html/real_time_system_conditions.html: 0 characters\n",
      "Fetching content and title for https://www.abc.net.au/news/2024-10-13/australian-coal-plant-in-extraordinary-survival-experiment/104461504...\n",
      "Fetching content and title for https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind...\n",
      "Attempt 1 failed for https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind: 403 Client Error: Forbidden for url: https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind, content length: 5450\n",
      "Attempt 2 failed for https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind: 403 Client Error: Forbidden for url: https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind, content length: 5450\n",
      "Fetching content and title for https://blog.gridstatus.io/curtailment/...\n",
      "Fetching content and title for https://blog.gridstatus.io/spp-expansion-west/...\n",
      "Fetching content and title for https://www.eia.gov/outlooks/steo/...\n",
      "Raw content and titles saved to links_with_raw_content.csv\n",
      "Processed 63 URLs\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.1: Fetch webpage content and titles\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fetch_webpage_content(url, retries=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "            text = ' '.join(element.get_text(strip=True) for element in text_elements)\n",
    "            if len(text) < 100:\n",
    "                print(f\"Insufficient content for {url}: {len(text)} characters\")\n",
    "                return \"\", \"\"\n",
    "            title = soup.find('title').text if soup.find('title') else url\n",
    "            return text[:5000], title[:255]\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed for {url}: {e}, content length: {len(response.text) if 'response' in locals() else 0}\")\n",
    "            if attempt == retries - 1:\n",
    "                return \"\", url\n",
    "    return \"\", url\n",
    "\n",
    "csv_path = \"links.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"{csv_path} not found\")\n",
    "links_df = pd.read_csv(csv_path)\n",
    "\n",
    "links_df[\"title\"] = \"\"\n",
    "links_df[\"content\"] = \"\"\n",
    "for index, row in links_df.iterrows():\n",
    "    url = row['url']\n",
    "    print(f\"Fetching content and title for {url}...\")\n",
    "    content, title = fetch_webpage_content(url)\n",
    "    links_df.at[index, 'content'] = content\n",
    "    links_df.at[index, 'title'] = title\n",
    "\n",
    "links_df.to_csv(\"links_with_raw_content.csv\", index=False)\n",
    "print(f\"Raw content and titles saved to links_with_raw_content.csv\")\n",
    "print(f\"Processed {len(links_df)} URLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning content for https://speakerdeck.com/gaelvaroquaux/open-source-software-how-to-live-long-and-go-far...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://github.com/jackboyla/GLiREL...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.latencyconf.io/sessions/pandas-should-go-extinct...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://orbae.adastra.eco/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://cambridge-intelligence.com/mapweave/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://holonetgalacticmap-frontend.vercel.app/sparql...\n",
      "Cleaning content for https://arxiv.org/pdf/2502.13025...\n",
      "Cleaning content for https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://enterprise-knowledge.com/the-resource-description-framework-rdf/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://blog.kuzudb.com/post/kuzu-wasm-rag/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://github.com/Manirevuri/arangodb-hackathon...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://2024.connected-data.london/speakers/urbashi-mitra/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://darrendevitt.com/all-fhir-concepts-can-be-explained-simply/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.sciencedirect.com/science/article/pii/S1532046422002064...\n",
      "Cleaning content for https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98...\n",
      "Error processing content: Extra data: line 2 column 1 (char 145)\n",
      "Cleaning content for https://link.springer.com/journal/10506...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.occrp.org/en/project/cyprus-confidential/billionaire-roman-abramovichs-company-set-up-fake-superyacht-chartering-scheme-in-apparent-attempt-to-evade-millions-in-taxes...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://discuss.opensanctions.org/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 146)\n",
      "Cleaning content for https://blog.opencorporates.com/2025/02/13/getting-started-with-the-opencorporates-api/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 146)\n",
      "Cleaning content for https://www.buzzsprout.com/242645/episodes/16799543...\n",
      "Error processing content: Extra data: line 2 column 1 (char 146)\n",
      "Cleaning content for https://www.unodc.org/unodc/en/data-and-analysis/tip-studies.html...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.occrp.org/en/project/scam-empire/scam-operations-relied-on-third-party-marketing-companies-for-steady-stream-of-potential-victims...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://bods-data.openownership.org/source/gleif_version_0_4/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://eiti.org/using-eiti-data...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://mweiti.gov.mw/index.php/reports/details/761...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://globalenergymonitor.org/projects/global-energy-ownership-tracker/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.moodys.com/web/en/us/kyc/resources/insights/how-ai-is-enhancing-ubo-discovery-and-support-reporting-requirements-globally.html...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://oecdstatistics.blog/2019/07/04/the-adima-database-on-multinational-enterprises/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://oecdstatistics.blog/2025/02/21/monitoring-multinational-enterprises-how-the-oecd-and-unsd-are-harnessing-open-data/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.taxobservatory.eu/publication/the-end-of-londongrad-ownership-transparency-and-offshore-investment-in-real-estate/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_a_new_era_of_private_sector_collaboration_to_detect_economic_crime_-_policy_discussion_paper_-_march_2025_-_final.pdf...\n",
      "Cleaning content for https://www.kharon.com/brief/outbound-investment-rules-china-hong-kong...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.gao.gov/products/gao-25-107403...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://hoeringsportalen.dk/Hearing/Details/69602...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://ubm.se/publikationer/publikationer/2025-03-13-kunskapsrapport---avancerade-angrepp-mot-valfardssystemen...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://senzing.com/daniel-silva-prudential-senzing-global-user-conference/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://graphaware.com/resources/streamlining-criminal-assets-confiscation/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://graphaware.com/law-enforcement/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://graphaware.com/blog/aml-investigations-detecting-risk-transactions/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5120765...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.powermag.com/software-hardware-innovation-all-needed-to-upgrade-the-power-grid/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://wattclarity.com.au/articles/2025/02/nemde-nightmares-parallel-pathways-and-clashing-constraints/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://mahasldc.in/wp-content/reports/other/Report_on_Optimizing_Power_Despatch.pdf...\n",
      "Cleaning content for https://github.com/kyribaker/7bus_LMPs...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.ercot.com/content/cdr/html/real_time_system_conditions.html...\n",
      "Cleaning content for https://www.abc.net.au/news/2024-10-13/australian-coal-plant-in-extraordinary-survival-experiment/104461504...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.nrdc.org/resources/uneconomic-coal-costs-miso-ratepayers-1-billion-and-curtails-400-mw-wind...\n",
      "Cleaning content for https://blog.gridstatus.io/curtailment/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://blog.gridstatus.io/spp-expansion-west/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaning content for https://www.eia.gov/outlooks/steo/...\n",
      "Error processing content: Extra data: line 2 column 1 (char 147)\n",
      "Cleaned content saved to links_with_cleaned_content.csv\n",
      "Cleaning log saved to cleaning_log.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.2: Clean fetched content with Ollama (Mistral 7B) using Pydantic\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ContentClassification(BaseModel):\n",
    "    garbage_text: str = Field(..., description=\"Irrelevant content (e.g., ads, navigation, boilerplate)\", min_length=0)\n",
    "    cleaned_content: str = Field(..., description=\"Main meaningful content, cleaned and formatted\", min_length=0)\n",
    "    unsure_content: str = Field(..., description=\"Content that is ambiguous or unclear\", min_length=0)\n",
    "\n",
    "def clean_content_with_llm(raw_content: str, model: str = \"mistral:7b-instruct-v0.3-q4_0\", \n",
    "                          endpoint: str = \"http://localhost:11434/api/chat\") -> tuple[str, str, str]:\n",
    "    if not isinstance(raw_content, str) or not raw_content or len(raw_content.strip()) < 100:\n",
    "        return \"\", \"\", \"\"\n",
    "    prompt = (\n",
    "        \"You are an expert at cleaning noisy text data. Analyze the following text and categorize it into three parts: \"\n",
    "        \"1. 'garbage_text': Irrelevant content (e.g., advertisements, navigation menus, boilerplate, footers). \"\n",
    "        \"2. 'cleaned_content': The main meaningful content, reformatted clearly (e.g., paragraphs or bullet points). \"\n",
    "        \"3. 'unsure_content': Text that is ambiguous or unclear if it belongs to the main content or garbage. \"\n",
    "        \"Return a JSON object with these three fields, wrapped in triple backticks (```json\\n{}\\n```). \"\n",
    "        \"Do not add or invent information; only categorize and reformat the input. \"\n",
    "        \"Example:\\n\"\n",
    "        \"```json\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"garbage_text\\\": \\\"Navbar: Home | About | Contact\\\",\\n\"\n",
    "        \"  \\\"cleaned_content\\\": \\\"This is the main article content.\\\",\\n\"\n",
    "        \"  \\\"unsure_content\\\": \\\"Posted by Admin\\\"\\n\"\n",
    "        \"}\\n\"\n",
    "        \"```\\n\"\n",
    "        \"Raw text:\\n\"\n",
    "        f\"{raw_content[:5000]}\\n\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.3\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint, json=payload, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        raw_response = response.json()[\"message\"][\"content\"].strip()\n",
    "        if raw_response.startswith('```json'):\n",
    "            raw_response = raw_response[7:].rsplit('```', 1)[0].strip()\n",
    "        result = json.loads(raw_response)\n",
    "        classification = ContentClassification.model_validate(result)\n",
    "        return classification.garbage_text, classification.cleaned_content, classification.unsure_content\n",
    "    except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "        print(f\"Error processing content: {e}\")\n",
    "        return \"\", raw_content, \"\"\n",
    "\n",
    "links_df = pd.read_csv(\"links_with_raw_content.csv\")\n",
    "cleaning_log = []\n",
    "for index, row in links_df.iterrows():\n",
    "    url = row['url']\n",
    "    print(f\"Cleaning content for {url}...\")\n",
    "    content = row['content']\n",
    "    garbage, cleaned, unsure = clean_content_with_llm(content)\n",
    "    links_df.at[index, 'content'] = cleaned\n",
    "    cleaning_log.append({\"url\": url, \"garbage_text\": garbage, \"unsure_content\": unsure})\n",
    "\n",
    "links_df.to_csv(\"links_with_cleaned_content.csv\", index=False)\n",
    "pd.DataFrame(cleaning_log).to_csv(\"cleaning_log.csv\", index=False)\n",
    "print(f\"Cleaned content saved to links_with_cleaned_content.csv\")\n",
    "print(f\"Cleaning log saved to cleaning_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed URLs appended to links_please_review.csv: 7 URLs\n",
      "CSV with titles, cleaned content, and empty metadata fields saved to links_with_content.csv\n",
      "Processed 56 valid URLs\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.3: Filter failed URLs and initialize metadata fields\n",
    "import pandas as pd\n",
    "\n",
    "links_df = pd.read_csv(\"links_with_cleaned_content.csv\")\n",
    "failed_urls = []\n",
    "for index, row in links_df.iterrows():\n",
    "    url = row['url']\n",
    "    content = row['content']\n",
    "    if not isinstance(content, str) or not content or len(content.strip()) < 100:\n",
    "        failed_urls.append({\"url\": url, \"reason\": \"Insufficient content after cleaning\"})\n",
    "    links_df.at[index, 'category'] = \"\"\n",
    "    links_df.at[index, 'keyword'] = \"\"\n",
    "    links_df.at[index, 'category_explanation'] = \"\"\n",
    "    links_df.at[index, 'keyword_explanation'] = \"\"\n",
    "\n",
    "failed_df = pd.DataFrame(failed_urls)\n",
    "if not failed_df.empty:\n",
    "    failed_df.to_csv(\"links_please_review.csv\", index=False, mode='a', header=not os.path.exists(\"links_please_review.csv\"))\n",
    "    print(f\"Failed URLs appended to links_please_review.csv: {len(failed_df)} URLs\")\n",
    "\n",
    "links_df = links_df[links_df['content'].apply(lambda x: isinstance(x, str) and len(x.strip()) >= 100)]\n",
    "links_df.to_csv(\"links_with_content.csv\", index=False)\n",
    "print(f\"CSV with titles, cleaned content, and empty metadata fields saved to links_with_content.csv\")\n",
    "print(f\"Processed {len(links_df)} valid URLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing https://speakerdeck.com/gaelvaroquaux/open-source-software-how-to-live-long-and-go-far for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"general tools\",\n",
      "        \"keywords\": [\"open-source software\", \"Python\", \"community\"],\n",
      "        \"category_explanation\": \"The article provides a guide to building open-source softwa...\n",
      "Processing https://medium.com/@seanjtaylor/a-personal-retrospective-on-prophet-f223c2378985 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"forecasting library\", \"Prophet\", \"time-series\"],\n",
      "        \"category_explanation\": \"The article discusses an AI tool (Prophet) used fo...\n",
      "Processing https://github.com/jackboyla/GLiREL for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"relation extraction\", \"named entity recognition\", \"spacy\"],\n",
      "        \"category_explanation\": \"The article discusses an AI model for r...\n",
      "Processing https://www.latencyconf.io/sessions/pandas-should-go-extinct for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"general tools\",\n",
      "        \"keywords\": [\"in-memory analytics\", \"database\", \"Databricks\"],\n",
      "        \"category_explanation\": \"The article discusses a tool (a database) that is used fo...\n",
      "Processing https://orbae.adastra.eco/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"environmental sustainability\",\n",
      "        \"keywords\": [\"land conversion\", \"agriculture emissions\", \"Orbae\"],\n",
      "        \"category_explanation\": \"The article discusses a technology (Or...\n",
      "Processing https://cambridge-intelligence.com/mapweave/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"graph technologies\",\n",
      "        \"keywords\": [\"geospatial visualization\", \"network analysis\", \"real-time data insights\"],\n",
      "        \"category_explanation\": \"The article discusses a ge...\n",
      "Processing https://github.com/yWorks/yfiles-jupyter-graphs-for-sparql for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"graph technologies\",\n",
      "        \"keywords\": [\"SPARQL\", \"RDF databases\", \"yFiles Graphs for Jupyter\"],\n",
      "        \"category_explanation\": \"The article discusses a tool for visualizing ...\n",
      "Processing https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"graph technologies\",\n",
      "        \"keywords\": [\"knowledge graph\", \"graph database\", \"AI in production\"],\n",
      "        \"category_explanation\": \"The article discusses the role of graph data...\n",
      "Processing https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"knowledge graph\", \"large language model\", \"MongoDB\"],\n",
      "        \"category_explanation\": \"The article discusses the use of AI, specific...\n",
      "Processing https://enterprise-knowledge.com/the-resource-description-framework-rdf/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"graph technologies\",\n",
      "        \"keywords\": [\"RDF\", \"knowledge graph\", \"semantic web\"],\n",
      "        \"category_explanation\": \"The article discusses the Resource Description Framework (R...\n",
      "Processing https://medium.com/oracledevs/validating-graph-data-with-shacl-using-oracle-rdf-graph-adapter-for-eclipse-rdf4j-09327042f530 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"graph technologies\",\n",
      "        \"keywords\": [\"RDF graph\", \"SHACL validation\", \"Oracle RDF Graph Adapter\"],\n",
      "        \"category_explanation\": \"The article discusses the use of SHACL f...\n",
      "Processing https://blog.kuzudb.com/post/kuzu-wasm-rag/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"graph technologies\",\n",
      "        \"keywords\": [\"Graph RAG\", \"Kuzu-Wasm\", \"WebAssembly\"],\n",
      "        \"category_explanation\": \"The article discusses the use of WebAssembly version of Kuzu...\n",
      "Processing https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"healthcare data\",\n",
      "        \"keywords\": [\"unstructured data\", \"graph database\", \"LLMs\"],\n",
      "        \"category_explanation\": \"The article discusses the use of graph databases and LLMs...\n",
      "Processing https://medium.com/@mcgeehan/building-a-hybrid-vector-search-database-with-arrow-and-duckdb-07ebc049bc1f for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"federated search\",\n",
      "        \"keywords\": [\"vector database\", \"HNSW\", \"Apache Arrow\", \"DuckDB\"],\n",
      "        \"category_explanation\": \"The article discusses a hybrid vector database sol...\n",
      "Error processing content: 1 validation error for ArticleClassification\n",
      "keywords\n",
      "  List should have at most 3 items after validation, not 4 [type=too_long, input_value=['vector database', 'HNSW...Apache Arrow', 'DuckDB'], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/too_long\n",
      "Processing https://github.com/Manirevuri/arangodb-hackathon for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"CVE graph database\", \"AI agent\", \"natural language query\"],\n",
      "        \"category_explanation\": \"The article discusses an AI tool for an...\n",
      "Processing https://medium.com/@tomzeppenfeldt/querying-an-erp-using-an-ai-configuration-in-graphileon-c667f21f5b51 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"AI configuration\", \"Graphileon\", \"ERP system\"],\n",
      "        \"category_explanation\": \"The article discusses the use of AI in configuring ...\n",
      "Processing https://2024.connected-data.london/speakers/urbashi-mitra/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"machine learning\", \"data science\", \"award\"],\n",
      "        \"category_explanation\": \"The article discusses AI research in the field of data...\n",
      "Processing https://darrendevitt.com/all-fhir-concepts-can-be-explained-simply/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"healthcare data\",\n",
      "        \"keywords\": [\"FHIR\", \"healthcare interoperability\"],\n",
      "        \"category_explanation\": \"The article focuses on FHIR, a healthcare data standard.\",\n",
      "      ...\n",
      "Processing https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"healthcare data\",\n",
      "        \"keywords\": [\"FHIR\", \"Retrieval Augmented Generation (RAG)\", \"Linked Data\"],\n",
      "        \"category_explanation\": \"The article discusses the use of FHIR for...\n",
      "Processing https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"Large Language Models (LLMs)\", \"Retrieval Augmented Generation (RAG)\"],\n",
      "        \"category_explanation\": \"The article discusses the u...\n",
      "Processing https://link.springer.com/journal/10506 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"ai and legal systems\",\n",
      "        \"keywords\": [\"artificial intelligence\", \"legal domain\", \"machine learning\"],\n",
      "        \"category_explanation\": \"The article discusses the applicatio...\n",
      "Processing https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"federated search\",\n",
      "        \"keywords\": [\"beneficial ownership\", \"multi-country search\", \"data access\"],\n",
      "        \"category_explanation\": \"The article discusses the development of...\n",
      "Processing https://www.occrp.org/en/project/cyprus-confidential/billionaire-roman-abramovichs-company-set-up-fake-superyacht-chartering-scheme-in-apparent-attempt-to-evade-millions-in-taxes for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"superyacht\", \"tax evasion\", \"offshore trust\"],\n",
      "        \"category_explanation\": \"The article discusses a financial crime involv...\n",
      "Processing https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"money laundering\", \"offshore accounts\", \"proxy directors\"],\n",
      "        \"category_explanation\": \"The article discusses the use of ...\n",
      "Processing https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"Azerbaijani Laundromat\", \"Danske Bank Estonia\", \"money laundering\"],\n",
      "        \"category_explanation\": \"The article discusses an i...\n",
      "Processing https://discuss.opensanctions.org/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "    \"category\": \"financial crime technology\",\n",
      "    \"keywords\": [\"OpenSanctions\", \"API\", \"bulk data\"],\n",
      "    \"category_explanation\": \"The article discusses a financial crime technology tool named OpenSa...\n",
      "Processing https://blog.opencorporates.com/2025/02/13/getting-started-with-the-opencorporates-api/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"OpenCorporates API\", \"company data\", \"search\"],\n",
      "        \"category_explanation\": \"The article discusses a tool used for accessi...\n",
      "Processing https://www.buzzsprout.com/242645/episodes/16799543 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"suspicious activity reports\", \"SARs\"],\n",
      "        \"category_explanation\": \"The article discusses suspicious activity reports, a c...\n",
      "Processing https://www.unodc.org/unodc/en/data-and-analysis/tip-studies.html for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"trafficking in persons\", \"smuggling of migrants\"],\n",
      "        \"category_explanation\": \"The article discusses the study on organized...\n",
      "Processing https://www.which.co.uk/news/article/scam-empire-inside-the-275m-fraud-call-centre-operations-aP3Kc4c9HWd7 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"investment fraud\", \"call center operations\"],\n",
      "        \"category_explanation\": \"The article discusses a large-scale organized inv...\n",
      "Processing https://www.occrp.org/en/project/scam-empire/scam-operations-relied-on-third-party-marketing-companies-for-steady-stream-of-potential-victims for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"scam operation\", \"affiliate marketing\"],\n",
      "        \"category_explanation\": \"The article discusses a large-scale scam operation rel...\n",
      "Processing https://github.com/DAD-CDM/dad-cdm-tsc/blob/main/DAD-CDM-Key-Findings-202502.md for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"general tools\",\n",
      "        \"keywords\": [\"navigation menu\", \"search code\", \"repositories\"],\n",
      "        \"category_explanation\": \"The article discusses a tool related to searching within...\n",
      "Processing https://bods-data.openownership.org/source/gleif_version_0_4/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"beneficial ownership\",\n",
      "        \"keywords\": [\"LEI\", \"GLEIF\", \"Open Ownership Data Standard\"],\n",
      "        \"category_explanation\": \"The article discusses the analysis of beneficial ow...\n",
      "Processing https://eiti.org/using-eiti-data for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"federated search\",\n",
      "        \"keywords\": [\"EITI data\", \"natural resource governance\"],\n",
      "        \"category_explanation\": \"The article discusses the use of EITI data for federated se...\n",
      "Processing https://mweiti.gov.mw/index.php/reports/details/761 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"beneficial ownership\", \"mining industry\", \"Malawi\"],\n",
      "        \"category_explanation\": \"The article discusses the financial aspe...\n",
      "Processing https://globalenergymonitor.org/projects/global-energy-ownership-tracker/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"energy projects\", \"ownership data\", \"chain of ownership\"],\n",
      "        \"category_explanation\": \"The article discusses a technology...\n",
      "Processing https://www.moodys.com/web/en/us/kyc/resources/insights/how-ai-is-enhancing-ubo-discovery-and-support-reporting-requirements-globally.html for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"AI\", \"UBO discovery\", \"data analysis\"],\n",
      "        \"category_explanation\": \"The article discusses the application of AI in financ...\n",
      "Processing https://oecdstatistics.blog/2019/07/04/the-adima-database-on-multinational-enterprises/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"MNEs\", \"taxes\", \"Effective Tax Rate\"],\n",
      "        \"category_explanation\": \"The article discusses a database (ADIMA) that provides...\n",
      "Processing https://oecdstatistics.blog/2025/02/21/monitoring-multinational-enterprises-how-the-oecd-and-unsd-are-harnessing-open-data/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"multinational enterprises\", \"global economy\", \"data platform\"],\n",
      "        \"category_explanation\": \"The article discusses a data pl...\n",
      "Processing https://www.taxobservatory.eu/publication/the-end-of-londongrad-ownership-transparency-and-offshore-investment-in-real-estate/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"beneficial ownership transparency\", \"offshore investment\", \"real estate\"],\n",
      "        \"category_explanation\": \"The article discus...\n",
      "Processing https://www.kharon.com/brief/outbound-investment-rules-china-hong-kong for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"legal systems\",\n",
      "        \"keywords\": [\"privacy policy\", \"terms of use\", \"patents\"],\n",
      "        \"category_explanation\": \"The article discusses legal aspects related to the company's ...\n",
      "Processing https://www.gao.gov/products/gao-25-107403 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"beneficial ownership\", \"Financial Crimes Enforcement Network (FinCEN)\", \"data protection\"],\n",
      "        \"category_explanation\": \"T...\n",
      "Processing https://hoeringsportalen.dk/Hearing/Details/69602 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"legal systems\",\n",
      "        \"keywords\": [\"law change\", \"company law\", \"real owner access\"],\n",
      "        \"category_explanation\": \"The article discusses a proposed law change related to c...\n",
      "Processing https://ubm.se/publikationer/publikationer/2025-03-13-kunskapsrapport---avancerade-angrepp-mot-valfardssystemen for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"fraudulent companies\", \"identity abuse\", \"social security\"],\n",
      "        \"category_explanation\": \"The article discusses advanced att...\n",
      "Processing https://senzing.com/daniel-silva-prudential-senzing-global-user-conference/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"insurance fraud\", \"data analytics\", \"legacy data\"],\n",
      "        \"category_explanation\": \"The article discusses the challenges and ...\n",
      "Processing https://graphaware.com/resources/streamlining-criminal-assets-confiscation/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"graph technology\", \"criminal assets confiscation\", \"investigation\"],\n",
      "        \"category_explanation\": \"The article discusses th...\n",
      "Processing https://graphaware.com/law-enforcement/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"organized crime analysis\",\n",
      "        \"keywords\": [\"connected data analytics\", \"graph technology\"],\n",
      "        \"category_explanation\": \"The article discusses the use of connected data...\n",
      "Processing https://graphaware.com/blog/aml-investigations-detecting-risk-transactions/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"financial crime technology\",\n",
      "        \"keywords\": [\"AML investigations\", \"network analytics\", \"connected data analysis\"],\n",
      "        \"category_explanation\": \"The article discusses t...\n",
      "Processing https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5120765 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"corporate governance\",\n",
      "        \"keywords\": [\"shareholder primacy\", \"Delaware law\", \"politicization\"],\n",
      "        \"category_explanation\": \"The article discusses the governance struc...\n",
      "Processing https://www.powermag.com/software-hardware-innovation-all-needed-to-upgrade-the-power-grid/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"power and utilities\",\n",
      "        \"keywords\": [\"power grid\", \"enhancements\", \"reliability\"],\n",
      "        \"category_explanation\": \"The article discusses the power grid and its improvemen...\n",
      "Processing https://wattclarity.com.au/articles/2025/02/nemde-nightmares-parallel-pathways-and-clashing-constraints/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"federated search\",\n",
      "        \"keywords\": [\"NEMDE\", \"dispatch interval\", \"interconnector\"],\n",
      "        \"category_explanation\": \"The article discusses a federated search scenario in th...\n",
      "Processing https://github.com/kyribaker/7bus_LMPs for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"power and utilities\",\n",
      "        \"keywords\": [\"locational marginal prices\", \"DC optimal power flow\", \"7-bus system\"],\n",
      "        \"category_explanation\": \"The article discusses the man...\n",
      "Processing https://www.abc.net.au/news/2024-10-13/australian-coal-plant-in-extraordinary-survival-experiment/104461504 for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"power and utilities\",\n",
      "        \"keywords\": [\"coal-fired power\", \"renewable energy\", \"base-load electricity\"],\n",
      "        \"category_explanation\": \"The article discusses the challenge...\n",
      "Processing https://blog.gridstatus.io/curtailment/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"power and utilities\",\n",
      "        \"keywords\": [\"curtailment\", \"renewable energy\", \"electricity markets\"],\n",
      "        \"category_explanation\": \"The article discusses the concept, causes,...\n",
      "Processing https://blog.gridstatus.io/spp-expansion-west/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"power and utilities\",\n",
      "        \"keywords\": [\"US power grid\", \"RTO/ISO expansion\"],\n",
      "        \"category_explanation\": \"The article discusses the expansion of an organized electricit...\n",
      "Processing https://www.eia.gov/outlooks/steo/ for categorization and keywords...\n",
      "Raw LLM response for content: {\n",
      "        \"category\": \"power and utilities\",\n",
      "        \"keywords\": [\"crude oil\", \"natural gas\", \"electricity\"],\n",
      "        \"category_explanation\": \"The article provides independent statistics and analysis ...\n",
      "Failed processing saved to failed_processing.csv: 1 URLs\n",
      "Updated CSV with titles, content, categories, keywords, and explanations saved to links_with_metadata.csv\n",
      "Unique categories: ['general tools', 'ai and legal systems', 'environmental sustainability', 'graph technologies', 'healthcare data', 'uncategorized', 'federated search', 'financial crime technology', 'organized crime analysis', 'beneficial ownership', 'legal systems', 'corporate governance', 'power and utilities']\n",
      "Keyword distribution:\n",
      "knowledge graph         3\n",
      "beneficial ownership    3\n",
      "money laundering        2\n",
      "renewable energy        2\n",
      "machine learning        2\n",
      "                       ..\n",
      "US power grid           1\n",
      "RTO/ISO expansion       1\n",
      "crude oil               1\n",
      "natural gas             1\n",
      "electricity             1\n",
      "Name: count, Length: 145, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>keyword</th>\n",
       "      <th>category_explanation</th>\n",
       "      <th>keyword_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>https://ubm.se/publikationer/publikationer/202...</td>\n",
       "      <td>KunskapsÂ­rapport â Avancerade angrepp mot vÃ¤lf...</td>\n",
       "      <td>Till innehÃ¥ll DÃ¶lj navigering Utbetalningsmynd...</td>\n",
       "      <td>organized crime analysis</td>\n",
       "      <td>fraudulent companies, identity abuse, social s...</td>\n",
       "      <td>The article discusses advanced attacks on welf...</td>\n",
       "      <td>Fraudulent companies is the main actor in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://graphaware.com/law-enforcement/</td>\n",
       "      <td>Connected Data for Criminal Intelligence Analysis</td>\n",
       "      <td>Connected data analytics platform. Explore how...</td>\n",
       "      <td>organized crime analysis</td>\n",
       "      <td>connected data analytics, graph technology</td>\n",
       "      <td>The article discusses the use of connected dat...</td>\n",
       "      <td>Connected data analytics is the central concep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://oecdstatistics.blog/2019/07/04/the-adi...</td>\n",
       "      <td>The ADIMA database on Multinational Enterprises</td>\n",
       "      <td>Recent Posts Most Used Categories  The ADIMA d...</td>\n",
       "      <td>financial crime technology</td>\n",
       "      <td>MNEs, taxes, Effective Tax Rate</td>\n",
       "      <td>The article discusses a database (ADIMA) that ...</td>\n",
       "      <td>MNEs are the main subject of the article.; Tax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://www.gao.gov/products/gao-25-107403</td>\n",
       "      <td>Illicit Finance: Treasury's Initial Safeguards...</td>\n",
       "      <td>U.S. Government Accountability Office Breadcru...</td>\n",
       "      <td>financial crime technology</td>\n",
       "      <td>beneficial ownership, Financial Crimes Enforce...</td>\n",
       "      <td>The article discusses the U.S. government's ef...</td>\n",
       "      <td>Beneficial owners are a central concept in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://www.powermag.com/software-hardware-inn...</td>\n",
       "      <td>Software, Hardware, Innovation All Needed to U...</td>\n",
       "      <td>POWERis at the forefront of the global power m...</td>\n",
       "      <td>power and utilities</td>\n",
       "      <td>power grid, enhancements, reliability</td>\n",
       "      <td>The article discusses the power grid and its i...</td>\n",
       "      <td>Power grid is the main subject of the article....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "43  https://ubm.se/publikationer/publikationer/202...   \n",
       "46            https://graphaware.com/law-enforcement/   \n",
       "37  https://oecdstatistics.blog/2019/07/04/the-adi...   \n",
       "41         https://www.gao.gov/products/gao-25-107403   \n",
       "49  https://www.powermag.com/software-hardware-inn...   \n",
       "\n",
       "                                                title  \\\n",
       "43  KunskapsÂ­rapport â Avancerade angrepp mot vÃ¤lf...   \n",
       "46  Connected Data for Criminal Intelligence Analysis   \n",
       "37    The ADIMA database on Multinational Enterprises   \n",
       "41  Illicit Finance: Treasury's Initial Safeguards...   \n",
       "49  Software, Hardware, Innovation All Needed to U...   \n",
       "\n",
       "                                              content  \\\n",
       "43  Till innehÃ¥ll DÃ¶lj navigering Utbetalningsmynd...   \n",
       "46  Connected data analytics platform. Explore how...   \n",
       "37  Recent Posts Most Used Categories  The ADIMA d...   \n",
       "41  U.S. Government Accountability Office Breadcru...   \n",
       "49  POWERis at the forefront of the global power m...   \n",
       "\n",
       "                      category  \\\n",
       "43    organized crime analysis   \n",
       "46    organized crime analysis   \n",
       "37  financial crime technology   \n",
       "41  financial crime technology   \n",
       "49         power and utilities   \n",
       "\n",
       "                                              keyword  \\\n",
       "43  fraudulent companies, identity abuse, social s...   \n",
       "46         connected data analytics, graph technology   \n",
       "37                    MNEs, taxes, Effective Tax Rate   \n",
       "41  beneficial ownership, Financial Crimes Enforce...   \n",
       "49              power grid, enhancements, reliability   \n",
       "\n",
       "                                 category_explanation  \\\n",
       "43  The article discusses advanced attacks on welf...   \n",
       "46  The article discusses the use of connected dat...   \n",
       "37  The article discusses a database (ADIMA) that ...   \n",
       "41  The article discusses the U.S. government's ef...   \n",
       "49  The article discusses the power grid and its i...   \n",
       "\n",
       "                                  keyword_explanation  \n",
       "43  Fraudulent companies is the main actor in the ...  \n",
       "46  Connected data analytics is the central concep...  \n",
       "37  MNEs are the main subject of the article.; Tax...  \n",
       "41  Beneficial owners are a central concept in the...  \n",
       "49  Power grid is the main subject of the article....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ollama import Client\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "\n",
    "ollama_client = Client(host='http://localhost:11434')\n",
    "\n",
    "# Updated Pydantic model to handle up to three keywords\n",
    "class ArticleClassification(BaseModel):\n",
    "    category: str = Field(..., description=\"The assigned category (2-3 words)\", min_length=2, max_length=50)\n",
    "    keywords: list[str] = Field(..., description=\"Up to three key terms (1-2 words each)\", min_items=1, max_items=3)\n",
    "    category_explanation: str = Field(..., description=\"One sentence explaining the category choice\", min_length=10, max_length=200)\n",
    "    keyword_explanations: list[str] = Field(..., description=\"One sentence per keyword explaining the choice\", min_items=1, max_items=3)\n",
    "\n",
    "suggested_categories = [\n",
    "    \"general tools\", \"graph technologies\", \"healthcare data\", \"ai and legal systems\",\n",
    "    \"federated search\", \"organized crime analysis\", \"beneficial ownership\",\n",
    "    \"financial crime technology\", \"corporate governance\", \"power and utilities\"\n",
    "]\n",
    "\n",
    "def process_with_ollama(content, client, suggested_categories):\n",
    "    if not content or len(content.strip()) < 100:\n",
    "        return None\n",
    "    template = f\"\"\"\n",
    "    You are an expert at categorizing articles and extracting key terms. Analyze the article content and provide a structured JSON output with:\n",
    "    - \"category\": A category (2-3 words, from suggested categories: {', '.join(suggested_categories)} or a new one if none fit)\n",
    "    - \"keywords\": A list of up to three key terms (1-2 words each, specific and descriptive, e.g., 'knowledge graph', not 'data')\n",
    "    - \"category_explanation\": One sentence explaining the category choice\n",
    "    - \"keyword_explanations\": A list of one sentence per keyword explaining the choice\n",
    "    Return ONLY the JSON object, wrapped in triple backticks (```json\\n{{}}\\n```).\n",
    "    Example:\n",
    "    ```json\n",
    "    {{\n",
    "        \"category\": \"graph technologies\",\n",
    "        \"keywords\": [\"knowledge graph\", \"graph database\", \"semantic search\"],\n",
    "        \"category_explanation\": \"The article discusses graph-based data management.\",\n",
    "        \"keyword_explanations\": [\n",
    "            \"Knowledge graph is the central concept of the article.\",\n",
    "            \"Graph database is discussed as the technology used.\",\n",
    "            \"Semantic search is mentioned as an application.\"\n",
    "        ]\n",
    "    }}\n",
    "    ```\n",
    "    Content: {content[:2000]}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.generate(\n",
    "            model='mistral:7b-instruct-v0.3-q4_0',\n",
    "            prompt=template,\n",
    "            options={\"temperature\": 0.4}\n",
    "        )\n",
    "        raw_response = response['response'].strip()\n",
    "        if raw_response.startswith('```json'):\n",
    "            raw_response = raw_response[7:].rsplit('```', 1)[0].strip()\n",
    "        elif not raw_response.startswith('{'):\n",
    "            raise ValueError(\"Unexpected response format from Ollama\")\n",
    "        print(f\"Raw LLM response for content: {raw_response[:200]}...\")\n",
    "        result = json.loads(raw_response)\n",
    "        classification = ArticleClassification.model_validate(result)\n",
    "        return classification\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing content: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "links_df = pd.read_csv(\"links_with_content.csv\")\n",
    "failed_processing = []\n",
    "for index, row in links_df.iterrows():\n",
    "    url = row['url']\n",
    "    print(f\"Processing {url} for categorization and keywords...\")\n",
    "    content = row['content']\n",
    "    result = process_with_ollama(content, ollama_client, suggested_categories)\n",
    "    if result:\n",
    "        links_df.at[index, 'category'] = result.category\n",
    "        # Store keywords as a comma-separated string\n",
    "        links_df.at[index, 'keyword'] = \", \".join(result.keywords)\n",
    "        links_df.at[index, 'category_explanation'] = result.category_explanation\n",
    "        # Store keyword explanations as a semicolon-separated string\n",
    "        links_df.at[index, 'keyword_explanation'] = \"; \".join(result.keyword_explanations)\n",
    "    else:\n",
    "        links_df.at[index, 'category'] = \"uncategorized\"\n",
    "        links_df.at[index, 'keyword'] = \"none\"\n",
    "        links_df.at[index, 'category_explanation'] = \"Failed to process content.\"\n",
    "        links_df.at[index, 'keyword_explanation'] = \"Failed to extract keywords.\"\n",
    "        failed_processing.append({\"url\": url, \"reason\": \"Failed to generate meaningful category or keywords\"})\n",
    "\n",
    "failed_processing_df = pd.DataFrame(failed_processing)\n",
    "if not failed_processing_df.empty:\n",
    "    failed_processing_df.to_csv(\"failed_processing.csv\", index=False)\n",
    "    print(f\"Failed processing saved to failed_processing.csv: {len(failed_processing_df)} URLs\")\n",
    "\n",
    "links_df.to_csv(\"links_with_metadata.csv\", index=False)\n",
    "print(\"Updated CSV with titles, content, categories, keywords, and explanations saved to links_with_metadata.csv\")\n",
    "unique_categories = links_df['category'].unique().tolist()\n",
    "# Calculate keyword distribution\n",
    "keyword_list = []\n",
    "for keywords in links_df['keyword']:\n",
    "    if keywords and keywords != \"none\":\n",
    "        keyword_list.extend([k.strip() for k in keywords.split(\",\")])\n",
    "keyword_distribution = pd.Series(keyword_list).value_counts()\n",
    "print(f\"Unique categories: {unique_categories}\")\n",
    "print(f\"Keyword distribution:\\n{keyword_distribution}\")\n",
    "links_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 2: KÃZU DATABASE AND VISUALIZATION\n",
    "# ----------------------------------------\n",
    "# This section initializes the KÃ¹zu database, populates it with data from links_with_metadata.csv,\n",
    "# queries for interconnections, and visualizes the graph with yFiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing database at ..\\db\\graph_db\n",
      "Ensured database directory at ..\\db\\graph_db\n",
      "Existing tables: []\n",
      "Database schema created successfully.\n",
      "Schema verified: Link table exists.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Initialize KÃ¹zu database\n",
    "import kuzu\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Database path\n",
    "db_path = os.path.join(\"..\", \"db\", \"graph_db\")\n",
    "\n",
    "# Delete existing database only if a fresh start is needed\n",
    "if os.path.exists(db_path):\n",
    "    shutil.rmtree(db_path)\n",
    "    print(f\"Deleted existing database at {db_path}\")\n",
    "\n",
    "# Create database directory\n",
    "os.makedirs(db_path, exist_ok=True)\n",
    "print(f\"Ensured database directory at {db_path}\")\n",
    "\n",
    "# Initialize database and connection (persist across cells)\n",
    "try:\n",
    "    db = kuzu.Database(db_path)\n",
    "    conn = kuzu.Connection(db)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing KÃ¹zu database at {db_path}: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create schema if it doesn't exist\n",
    "try:\n",
    "    # Check if tables already exist\n",
    "    result = conn.execute(\"CALL show_tables() RETURN name\")\n",
    "    existing_tables = []\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        existing_tables.append(row[0])\n",
    "    print(f\"Existing tables: {existing_tables}\")\n",
    "\n",
    "    if \"Link\" not in existing_tables:\n",
    "        conn.execute(\"CREATE NODE TABLE Link(url STRING, category STRING, title STRING, keyword STRING, category_explanation STRING, keyword_explanation STRING, PRIMARY KEY(url))\")\n",
    "        conn.execute(\"CREATE NODE TABLE Category(name STRING, PRIMARY KEY(name))\")\n",
    "        conn.execute(\"CREATE NODE TABLE Keyword(name STRING, PRIMARY KEY(name))\")\n",
    "        conn.execute(\"CREATE REL TABLE BELONGS_TO(FROM Link TO Category)\")\n",
    "        conn.execute(\"CREATE REL TABLE HAS_KEYWORD(FROM Link TO Keyword)\")\n",
    "        print(\"Database schema created successfully.\")\n",
    "    else:\n",
    "        print(\"Schema already exists, skipping creation.\")\n",
    "\n",
    "    # Verify schema\n",
    "    result = conn.execute(\"CALL show_tables() RETURN name\")\n",
    "    tables = []\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        tables.append(row[0])\n",
    "    if \"Link\" not in tables:\n",
    "        raise ValueError(\"Link table not found in schema.\")\n",
    "    print(\"Schema verified: Link table exists.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing schema: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 55 valid links after removing failed entries.\n",
      "KÃ¹zu database populated successfully.\n",
      "Uncategorized nodes: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Populate KÃ¹zu database with links, categories, and keywords\n",
    "import kuzu\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "db_path = os.path.join(\"..\", \"db\", \"graph_db\")\n",
    "csv_path = \"links_with_metadata.csv\"\n",
    "\n",
    "try:\n",
    "    # Validate database and connection\n",
    "    if not ('db' in globals() and 'conn' in globals()):\n",
    "        raise ValueError(\"Database and connection not initialized. Run Cell 4 first.\")\n",
    "    if not os.path.exists(db_path):\n",
    "        raise FileNotFoundError(f\"Database path {db_path} not found. Run Cell 4 to initialize.\")\n",
    "\n",
    "    # Validate CSV\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"{csv_path} not found. Ensure Section 1 has generated links_with_metadata.csv.\")\n",
    "    links_df = pd.read_csv(csv_path)\n",
    "    required_columns = ['url', 'category', 'title', 'keyword', 'category_explanation', 'keyword_explanation', 'content']\n",
    "    missing_columns = [col for col in required_columns if col not in links_df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"CSV missing required columns: {missing_columns}\")\n",
    "\n",
    "    # Filter out failed links\n",
    "    links_df = links_df[\n",
    "        (links_df['content'].apply(lambda x: isinstance(x, str) and len(x.strip()) >= 100)) &\n",
    "        (links_df['category'] != \"uncategorized\") &\n",
    "        (links_df['keyword'] != \"none\")\n",
    "    ]\n",
    "    print(f\"Filtered to {len(links_df)} valid links after removing failed entries.\")\n",
    "    if links_df.empty:\n",
    "        raise ValueError(\"No valid links remain after filtering. Check Section 1 output.\")\n",
    "\n",
    "    # Verify schema\n",
    "    result = conn.execute(\"CALL show_tables() RETURN name\")\n",
    "    tables = []\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        tables.append(row[0])\n",
    "    if not all(table in tables for table in [\"Link\", \"Category\", \"Keyword\", \"BELONGS_TO\", \"HAS_KEYWORD\"]):\n",
    "        raise ValueError(\"Required tables or relationships missing. Run Cell 4 to recreate the schema.\")\n",
    "\n",
    "    # Batch insert categories\n",
    "    for category in links_df['category'].unique():\n",
    "        if pd.notna(category) and category != \"uncategorized\":\n",
    "            category = category.replace(\"'\", \"\\\\'\")\n",
    "            conn.execute(f\"MERGE (c:Category {{name: '{category}'}})\")\n",
    "\n",
    "    # Batch insert keywords\n",
    "    all_keywords = set()\n",
    "    for keywords in links_df['keyword']:\n",
    "        if pd.notna(keywords) and keywords != \"none\":\n",
    "            all_keywords.update(k.strip() for k in keywords.split(\",\") if k.strip())\n",
    "    for keyword in all_keywords:\n",
    "        if pd.notna(keyword):\n",
    "            keyword = keyword.replace(\"'\", \"\\\\'\")\n",
    "            conn.execute(f\"MERGE (k:Keyword {{name: '{keyword}'}})\")\n",
    "\n",
    "    # Insert links and relationships\n",
    "    for _, row in links_df.iterrows():\n",
    "        url = row['url'].replace(\"'\", \"\\\\'\")\n",
    "        category = row['category'].replace(\"'\", \"\\\\'\") if pd.notna(row['category']) else \"uncategorized\"\n",
    "        title = row['title'].replace(\"'\", \"\\\\'\") if pd.notna(row['title']) else \"\"\n",
    "        keyword = row['keyword'].replace(\"'\", \"\\\\'\") if pd.notna(row['keyword']) else \"none\"\n",
    "        category_explanation = row['category_explanation'].replace(\"'\", \"\\\\'\") if pd.notna(row['category_explanation']) else \"\"\n",
    "        keyword_explanation = row['keyword_explanation'].replace(\"'\", \"\\\\'\") if pd.notna(row['keyword_explanation']) else \"\"\n",
    "        \n",
    "        conn.execute(f\"\"\"\n",
    "            MERGE (l:Link {{url: '{url}'}})\n",
    "            SET l.category = '{category}',\n",
    "                l.title = '{title}',\n",
    "                l.keyword = '{keyword}',\n",
    "                l.category_explanation = '{category_explanation}',\n",
    "                l.keyword_explanation = '{keyword_explanation}'\n",
    "        \"\"\")\n",
    "        \n",
    "        if pd.notna(row['category']) and row['category'] != \"uncategorized\":\n",
    "            conn.execute(f\"\"\"\n",
    "                MATCH (l:Link {{url: '{url}'}}), (c:Category {{name: '{category}'}})\n",
    "                MERGE (l)-[:BELONGS_TO]->(c)\n",
    "            \"\"\")\n",
    "\n",
    "        if pd.notna(row['keyword']) and row['keyword'] != \"none\":\n",
    "            for keyword in row['keyword'].split(\",\"):\n",
    "                keyword = keyword.strip().replace(\"'\", \"\\\\'\")\n",
    "                if keyword:\n",
    "                    conn.execute(f\"\"\"\n",
    "                        MATCH (l:Link {{url: '{url}'}}), (k:Keyword {{name: '{keyword}'}})\n",
    "                        MERGE (l)-[:HAS_KEYWORD]->(k)\n",
    "                    \"\"\")\n",
    "\n",
    "    print(\"KÃ¹zu database populated successfully.\")\n",
    "    result = conn.execute(\"MATCH (l:Link) WHERE l.category = 'uncategorized' RETURN COUNT(l)\")\n",
    "    uncategorized_count = result.get_next()[0]\n",
    "    print(f\"Uncategorized nodes: {uncategorized_count}\")  # Should be 0 due to filtering\n",
    "    if uncategorized_count > 0:\n",
    "        print(\"Warning: Uncategorized nodes found despite filtering. Check data in links_with_metadata.csv.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error populating database: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Link nodes: 55\n",
      "Links with keywords: 156\n",
      "Links with categories: 55\n",
      "Interconnections between categories:\n",
      "                                                                                                                                    Link1_URL             Link1_Category                                                                                                                                     Link2_URL             Link2_Category                       Shared_Keyword\n",
      "                                                               https://medium.com/@samschifman/rag-on-fhir-with-knowledge-graphs-04d8e13ee96e            healthcare data                                              https://medium.com/enterprise-rag/why-lawyers-are-uniquely-suited-to-work-with-llms-bcc66d3dce98       ai and legal systems Retrieval Augmented Generation (RAG)\n",
      "                                                                                          https://mweiti.gov.mw/index.php/reports/details/761 financial crime technology                https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/           federated search                 beneficial ownership\n",
      "                                                                                                   https://www.gao.gov/products/gao-25-107403 financial crime technology                https://www.openownership.org/en/blog/lessons-from-building-a-prototype-single-search-tool-for-beneficial-ownership-registers/           federated search                 beneficial ownership\n",
      "                                                                           https://blog.kuzudb.com/post/unstructured-data-to-graph-baml-kuzu/            healthcare data https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63         graph technologies                       graph database\n",
      "                                                                                                      https://graphaware.com/law-enforcement/   organized crime analysis                                                                   https://graphaware.com/resources/streamlining-criminal-assets-confiscation/ financial crime technology                     graph technology\n",
      "https://medium.com/eqtventures/knowledge-graph-s-and-llm-based-ontologies-have-a-very-good-shot-at-unlocking-genai-in-production-1b167533ef63         graph technologies                                                             https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs       ai and legal systems                      knowledge graph\n",
      "                                                                     https://enterprise-knowledge.com/the-resource-description-framework-rdf/         graph technologies                                                             https://www.mongodb.com/blog/post/supercharge-ai-data-management-knowledge-graphs       ai and legal systems                      knowledge graph\n",
      "        https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-contract-factory-inside-danske-bank-estonias-money-laundering-machine financial crime technology                                                                      https://www.occrp.org/en/project/the-azerbaijani-laundromat/the-raw-data   organized crime analysis                     money laundering\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Query KÃ¹zu for interconnections between categories\n",
    "import kuzu\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "db_path = os.path.join(\"..\", \"db\", \"graph_db\")\n",
    "\n",
    "try:\n",
    "    # Validate database and connection\n",
    "    if not ('db' in globals() and 'conn' in globals()):\n",
    "        raise ValueError(\"Database and connection not initialized. Run Cell 4 first.\")\n",
    "    if not os.path.exists(db_path):\n",
    "        raise FileNotFoundError(f\"Database path {db_path} not found. Run Cell 4 to initialize.\")\n",
    "\n",
    "    # Diagnostic queries\n",
    "    result = conn.execute(\"MATCH (l:Link) RETURN COUNT(l)\")\n",
    "    link_count = result.get_next()[0]\n",
    "    print(f\"Total Link nodes: {link_count}\")\n",
    "    if link_count == 0:\n",
    "        raise ValueError(\"No Link nodes found. Run Cell 5 to populate the database.\")\n",
    "\n",
    "    result = conn.execute(\"MATCH (l:Link)-[:HAS_KEYWORD]->(k:Keyword) RETURN COUNT(l)\")\n",
    "    print(f\"Links with keywords: {result.get_next()[0]}\")\n",
    "    result = conn.execute(\"MATCH (l:Link)-[:BELONGS_TO]->(c:Category) RETURN COUNT(l)\")\n",
    "    print(f\"Links with categories: {result.get_next()[0]}\")\n",
    "\n",
    "    # Query interconnections\n",
    "    results = conn.execute(\"\"\"\n",
    "        MATCH (l1:Link)-[:HAS_KEYWORD]->(k:Keyword)<-[:HAS_KEYWORD]-(l2:Link),\n",
    "              (l1)-[:BELONGS_TO]->(c1:Category),\n",
    "              (l2)-[:BELONGS_TO]->(c2:Category)\n",
    "        WHERE c1.name <> c2.name AND l1.url < l2.url\n",
    "        RETURN l1.url, l1.category, l2.url, l2.category, k.name AS shared_keyword\n",
    "        ORDER BY k.name, l1.category, l2.category\n",
    "        LIMIT 100\n",
    "    \"\"\")\n",
    "\n",
    "    interconnections = []\n",
    "    while results.has_next():\n",
    "        row = results.get_next()\n",
    "        interconnections.append({\n",
    "            \"Link1_URL\": row[0],\n",
    "            \"Link1_Category\": row[1],\n",
    "            \"Link2_URL\": row[2],\n",
    "            \"Link2_Category\": row[3],\n",
    "            \"Shared_Keyword\": row[4]\n",
    "        })\n",
    "\n",
    "    interconnections_df = pd.DataFrame(interconnections)\n",
    "    if not interconnections_df.empty:\n",
    "        print(\"Interconnections between categories:\")\n",
    "        print(interconnections_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No interconnections found. Verify keywords and categories in Cell 5 output.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error querying database: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orphaned nodes cleaned.\n",
      "Total Link nodes: 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21b073602574e3bb0ea801642927286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph visualization completed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Clean KÃ¹zu graph and visualize with yFiles\n",
    "import kuzu\n",
    "import os\n",
    "import pandas as pd\n",
    "try:\n",
    "    from yfiles_jupyter_graphs import GraphWidget\n",
    "except ImportError:\n",
    "    raise ImportError(\"Install yfiles-jupyter-graphs: pip install yfiles-jupyter-graphs\")\n",
    "\n",
    "db_path = os.path.join(\"..\", \"db\", \"graph_db\")\n",
    "\n",
    "def clean_database():\n",
    "    try:\n",
    "        # Validate database and connection\n",
    "        if not ('db' in globals() and 'conn' in globals()):\n",
    "            raise ValueError(\"Database and connection not initialized. Run Cell 4 first.\")\n",
    "        if not os.path.exists(db_path):\n",
    "            raise FileNotFoundError(f\"Database path {db_path} not found.\")\n",
    "\n",
    "        # Verify no uncategorized links exist (due to filtering in Cell 5)\n",
    "        result = conn.execute(\"MATCH (l:Link) WHERE l.category = 'uncategorized' RETURN l.url, l.title\")\n",
    "        uncategorized = []\n",
    "        while result.has_next():\n",
    "            row = result.get_next()\n",
    "            uncategorized.append({\"url\": row[0], \"title\": row[1] or \"No Title\"})\n",
    "        if uncategorized:\n",
    "            print(f\"Warning: Found {len(uncategorized)} uncategorized links despite filtering.\")\n",
    "            pd.DataFrame(uncategorized).to_csv(\"uncategorized_links.csv\", index=False)\n",
    "\n",
    "        # Clean orphaned nodes\n",
    "        conn.execute(\"MATCH (c:Category) WHERE NOT (c)<-[:BELONGS_TO]-() DELETE c\")\n",
    "        conn.execute(\"MATCH (k:Keyword) WHERE NOT (k)<-[:HAS_KEYWORD]-() DELETE k\")\n",
    "        print(\"Orphaned nodes cleaned.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning database: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    clean_database()\n",
    "\n",
    "    # Validate data\n",
    "    result = conn.execute(\"MATCH (l:Link) RETURN COUNT(l)\")\n",
    "    link_count = result.get_next()[0]\n",
    "    print(f\"Total Link nodes: {link_count}\")\n",
    "    if link_count == 0:\n",
    "        raise ValueError(\"No Link nodes found. Run Cell 5 to populate the database.\")\n",
    "\n",
    "    nodes = []\n",
    "    edges = []\n",
    "\n",
    "    # Add Link nodes\n",
    "    result = conn.execute(\"MATCH (l:Link) RETURN l.url, l.category, l.title, l.keyword LIMIT 50\")\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        nodes.append({\n",
    "            \"id\": row[0],\n",
    "            \"properties\": {\n",
    "                \"type\": \"Link\",\n",
    "                \"label\": row[2] or row[0],\n",
    "                \"category\": row[1],\n",
    "                \"keywords\": row[3]  # Include keywords for display\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Add Category nodes\n",
    "    result = conn.execute(\"MATCH (c:Category) RETURN c.name\")\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        nodes.append({\"id\": row[0], \"properties\": {\"type\": \"Category\", \"label\": row[0]}})\n",
    "\n",
    "    # Add Keyword nodes\n",
    "    result = conn.execute(\"MATCH (k:Keyword) RETURN k.name\")\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        nodes.append({\"id\": row[0], \"properties\": {\"type\": \"Keyword\", \"label\": row[0]}})\n",
    "\n",
    "    # Add BELONGS_TO edges\n",
    "    result = conn.execute(\"MATCH (l:Link)-[:BELONGS_TO]->(c:Category) RETURN l.url, c.name\")\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        edges.append({\"start\": row[0], \"end\": row[1], \"properties\": {\"type\": \"BELONGS_TO\"}})\n",
    "\n",
    "    # Add HAS_KEYWORD edges\n",
    "    result = conn.execute(\"MATCH (l:Link)-[:HAS_KEYWORD]->(k:Keyword) RETURN l.url, k.name\")\n",
    "    while result.has_next():\n",
    "        row = result.get_next()\n",
    "        edges.append({\"start\": row[0], \"end\": row[1], \"properties\": {\"type\": \"HAS_KEYWORD\"}})\n",
    "\n",
    "    # Visualize\n",
    "    w = GraphWidget()\n",
    "    w.nodes = nodes\n",
    "    w.edges = edges\n",
    "\n",
    "    def node_mappings(node):\n",
    "        node_type = node['properties']['type']\n",
    "        if node_type == \"Link\":\n",
    "            return {\"color\": \"#1E90FF\", \"shape\": \"rectangle\"}\n",
    "        elif node_type == \"Category\":\n",
    "            return {\"color\": \"#32CD32\", \"shape\": \"ellipse\"}\n",
    "        elif node_type == \"Keyword\":\n",
    "            return {\"color\": \"#FF4500\", \"shape\": \"triangle\"}\n",
    "        return {\"color\": \"#808080\", \"shape\": \"circle\"}\n",
    "\n",
    "    w.node_mappings = node_mappings\n",
    "\n",
    "    def edge_mappings(edge):\n",
    "        edge_type = edge['properties']['type']\n",
    "        if edge_type == \"BELONGS_TO\":\n",
    "            return {\"color\": \"#FFD700\"}\n",
    "        elif edge_type == \"HAS_KEYWORD\":\n",
    "            return {\"color\": \"#9932CC\"}\n",
    "        return {\"color\": \"#000000\"}\n",
    "\n",
    "    w.node_label_mapping = lambda node: node['properties']['label']\n",
    "    w.set_graph_layout(\"organic\")\n",
    "    w.show()\n",
    "    print(\"Graph visualization completed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error visualizing graph: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
